<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>Micro-Podcast</title>
    </head>
    <body>
        <div>
            gpt-3.5-turbo-16k offers 4 times the context length of gpt-3.5-turbo
            at twice the price: $0.003 per 1K input tokens and $0.004 per 1K
            output tokens. 16k context means the model can now support ~20 pages
            of text in a single request.
        </div>
    </body>
</html>
